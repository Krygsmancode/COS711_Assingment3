{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In data_preparation.ipynb\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress bars\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "# RAW_DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/Malaria_Categorization_Project/data/raw/'\n",
    "# PROCESSED_DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/Malaria_Categorization_Project/data/processed'\n",
    "RAW_DATA_DIR = GLOBAL_CONFIG_DATA_RAW_IMAGE_PATH\n",
    "PROCESSED_DATA_DIR = GLOBAL_CONFIG_DATA_PROCESSED_IMAGE_PATH\n",
    "\n",
    "\n",
    "# Create processed data directory if it doesn't exist\n",
    "if not os.path.exists(PROCESSED_DATA_DIR):\n",
    "    os.makedirs(PROCESSED_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw images: 3925\n"
     ]
    }
   ],
   "source": [
    "# List some files in the raw data directory\n",
    "raw_images = os.listdir(RAW_DATA_DIR)\n",
    "print(f\"Number of raw images: {len(raw_images)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, output_size=(224, 224)):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "    # Convert to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Remove non-cell parts (black areas)\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([50, 50, 50])\n",
    "    mask_black = cv2.inRange(img_rgb, lower_black, upper_black)\n",
    "    img_rgb[mask_black == 255] = [255, 255, 255]\n",
    "\n",
    "    # Resize image\n",
    "    img_resized = cv2.resize(img_rgb, output_size)\n",
    "\n",
    "    # Normalize pixel values (0 to 1)\n",
    "    img_normalized = img_resized / 255.0\n",
    "\n",
    "    return img_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3925/3925 [05:45<00:00, 11.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process and save all images\n",
    "for image_name in tqdm(raw_images):\n",
    "    image_path = os.path.join(RAW_DATA_DIR, image_name)\n",
    "    processed_image = preprocess_image(image_path)\n",
    "\n",
    "    if processed_image is not None:\n",
    "        # Convert back to uint8 for saving\n",
    "        processed_image_uint8 = (processed_image * 255).astype(np.uint8)\n",
    "        # Save processed image\n",
    "        save_path = os.path.join(PROCESSED_DATA_DIR, image_name)\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(processed_image_uint8, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Image_ID        class  confidence  ymin  xmin  ymax  xmax\n",
      "0  id_u3q6jdck4j.jpg  Trophozoite         1.0   712  1241   737  1270\n",
      "1  id_a6cl90trri.jpg  Trophozoite         1.0   558  1566   600  1604\n",
      "2  id_qvc2le9sm8.jpg  Trophozoite         1.0  1317  2788  1448  2914\n",
      "3  id_w8xnbd5rvm.jpg  Trophozoite         1.0   925  1744  1041  1823\n",
      "4  id_6dop09rk02.jpg          NEG         1.0     0     0     0     0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the training labels\n",
    "train_labels = pd.read_csv(GLOBAL_CONFIG_DATA_RAW_LABEL_PATH)\n",
    "\n",
    "# Display the first few rows\n",
    "print(train_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: ['Trophozoite' 'NEG' 'WBC']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique classes\n",
    "unique_classes = train_labels['class'].unique()\n",
    "print(f\"Unique classes: {unique_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Trophozoite    15838\n",
      "WBC             7004\n",
      "NEG              688\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts for each class\n",
    "class_counts = train_labels['class'].value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load your labels CSV\n",
    "labels_df = pd.read_csv(GLOBAL_CONFIG_DATA_RAW_LABEL_PATH)\n",
    "\n",
    "# Add 'augmented' column for original images\n",
    "labels_df['augmented'] = False\n",
    "\n",
    "# Paths setup\n",
    "images_path = GLOBAL_CONFIG_DATA_PROCESSED_IMAGE_PATH\n",
    "output_path = f'{GLOBAL_CONFIG_DATA_PATH}augmented_images/'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Copy original images to output_path\n",
    "for img_name in labels_df['Image_ID']:\n",
    "    src = os.path.join(images_path, img_name)\n",
    "    dst = os.path.join(output_path, img_name)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "def augment_class(images_path, class_df, class_name, target_count, output_path):\n",
    "    current_count = class_df.shape[0]\n",
    "    augment_needed = target_count - current_count\n",
    "\n",
    "    if augment_needed <= 0:\n",
    "        return []  # No augmentation needed\n",
    "\n",
    "    new_rows = []\n",
    "    aug_count = 0\n",
    "    image_indices = class_df.index.tolist()\n",
    "    num_images = len(image_indices)\n",
    "    image_counter = 0\n",
    "\n",
    "    while aug_count < augment_needed:\n",
    "        idx = image_indices[image_counter % num_images]\n",
    "        row = class_df.loc[idx]\n",
    "        image_path = os.path.join(images_path, row['Image_ID'])\n",
    "        img = load_img(image_path)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_path, save_prefix=f'aug_{class_name.lower()}_', save_format='jpg'):\n",
    "            new_image_id = f'aug_{class_name.lower()}_{aug_count}.jpg'\n",
    "            new_row = row.copy()\n",
    "            new_row['Image_ID'] = new_image_id\n",
    "            new_row['augmented'] = True\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "            aug_count += 1\n",
    "            if aug_count >= augment_needed:\n",
    "                break\n",
    "\n",
    "        image_counter += 1\n",
    "\n",
    "    return new_rows\n",
    "\n",
    "\n",
    "\n",
    "# Filter class DataFrames\n",
    "wbc_df = labels_df[labels_df['class'] == 'WBC']\n",
    "neg_df = labels_df[labels_df['class'] == 'NEG']\n",
    "\n",
    "\n",
    "# Augment WBC and NEG classes\n",
    "new_wbc_rows = augment_class(output_path, wbc_df, 'WBC', 15838, output_path)\n",
    "new_neg_rows = augment_class(output_path, neg_df, 'NEG', 15838, output_path)\n",
    "\n",
    "# Combine all labels\n",
    "new_df = pd.concat([labels_df, pd.DataFrame(new_wbc_rows), pd.DataFrame(new_neg_rows)], ignore_index=True)\n",
    "\n",
    "# Save the updated labels DataFrame\n",
    "new_df.to_csv(f'{GLOBAL_CONFIG_DATA_PATH}augmented_labels.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Image_ID        class  confidence  ymin  xmin  ymax  xmax  \\\n",
      "0  id_u3q6jdck4j.jpg  Trophozoite         1.0   712  1241   737  1270   \n",
      "1  id_a6cl90trri.jpg  Trophozoite         1.0   558  1566   600  1604   \n",
      "2  id_qvc2le9sm8.jpg  Trophozoite         1.0  1317  2788  1448  2914   \n",
      "3  id_w8xnbd5rvm.jpg  Trophozoite         1.0   925  1744  1041  1823   \n",
      "4  id_6dop09rk02.jpg          NEG         1.0     0     0     0     0   \n",
      "\n",
      "   augmented  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3      False  \n",
      "4      False  \n",
      "Unique classes: ['Trophozoite' 'NEG' 'WBC']\n",
      "class\n",
      "Trophozoite    15838\n",
      "NEG            15838\n",
      "WBC            15838\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the training labels\n",
    "train_labels = pd.read_csv(f'{GLOBAL_CONFIG_DATA_PATH}augmented_labels.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(train_labels.head())\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = train_labels['class'].unique()\n",
    "print(f\"Unique classes: {unique_classes}\")\n",
    "\n",
    "# Calculate the counts for each class\n",
    "class_counts = train_labels['class'].value_counts()\n",
    "print(class_counts)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
